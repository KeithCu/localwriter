# Example models file for OpenRouter endpoint.
#
# OpenRouter supports many models via a single endpoint.
# Set endpoint to https://openrouter.ai/api in the main config,
# then use this file to define available models.
#
# Place this file anywhere and point to it in:
#   Tools > Options > LocalWriter > Ai > Models File (YAML)

models:
  - id: "meta-llama/llama-3.3-70b-instruct"
    display_name: "Llama 3.3 70B Instruct"
    capability: text
    context_length: 128000
    notes: "Strong generalist, good tool calling, open weights (Meta)"
    priority: 9
    ids:
      openrouter: "meta-llama/llama-3.3-70b-instruct"

  - id: "google/gemma-3-27b-it"
    display_name: "Gemma 3 27B Instruct"
    capability: text
    context_length: 131072
    notes: "Fast, efficient, excellent instruction following (Google)"
    priority: 8
    ids:
      openrouter: "google/gemma-3-27b-it"

  - id: "mistralai/mistral-large-latest"
    display_name: "Mistral Large 3"
    capability: text
    context_length: 256000
    notes: "Top open-weight multimodal, agentic & tool strong (Mistral AI)"
    priority: 9
    ids:
      openrouter: "mistralai/mistral-large-latest"

  - id: "google/gemini-3.1-pro-preview"
    display_name: "Gemini 3.1 Pro Preview"
    capability: image
    context_length: 1000000
    notes: "Excellent vision + reasoning, 1M context (Google)"
    priority: 9
    ids:
      openrouter: "google/gemini-3.1-pro-preview"
