# core/document_tools.py â€” Writer document manipulation tools for AI chat sidebar.
# Provides JSON tool schemas (WRITER_TOOLS) and executor for the
# OpenAI-compatible tool-calling protocol.

import json
import inspect

from plugin.framework.logging import agent_log
from plugin.framework.tool_base import ToolBase
from plugin.framework.tool_registry import ToolRegistry
from plugin.framework.tool_context import ToolContext
from plugin.modules.writer.format_support import FORMAT_TOOLS, tool_get_document_content, tool_apply_document_content, tool_find_text
from plugin.modules.writer.outline import OUTLINE_TOOLS, tool_get_document_outline, tool_get_heading_content
from plugin.modules.writer.stats import STATS_TOOLS, tool_get_document_stats
from plugin.modules.writer.styles import STYLES_TOOLS, tool_list_styles, tool_get_style_info
from plugin.modules.writer.comments import COMMENTS_TOOLS, tool_list_comments, tool_add_comment, tool_delete_comment
from plugin.modules.writer.content import CONTENT_TOOLS, tool_read_paragraphs, tool_insert_at_paragraph
from plugin.modules.writer.tracking import TRACKING_TOOLS, tool_set_track_changes, tool_get_tracked_changes, tool_accept_all_changes, tool_reject_all_changes
from plugin.modules.writer.tables import TABLES_TOOLS, tool_list_tables, tool_read_table, tool_write_table_cell
from plugin.modules.ai.tools import WebResearchTool, GenerateImageTool, EditImageTool

WRITER_OPS_TOOLS = OUTLINE_TOOLS + STATS_TOOLS + STYLES_TOOLS + COMMENTS_TOOLS + CONTENT_TOOLS + TRACKING_TOOLS + TABLES_TOOLS
from plugin.modules.core.document import (
    get_document_length,
    is_writer,
    is_calc,
    is_draw,
    DocumentCache
)


WRITER_TOOLS = list(FORMAT_TOOLS) + WRITER_OPS_TOOLS


# ---------------------------------------------------------------------------
# Tool implementations
# ---------------------------------------------------------------------------

def tool_generate_image(model, ctx, args, status_callback=None):
    """Generate an image and insert it."""
    from plugin.framework.image_utils import ImageService
    from plugin.modules.core.image_tools import insert_image
    from plugin.modules.core.config import get_config_dict, as_bool, get_text_model, update_lru_history

    config = get_config_dict(ctx)
    service = ImageService(ctx, config)

    prompt = args.get("prompt")
    provider = args.get("provider", config.get("image_provider", "aihorde"))

    base_size = args.get("base_size", config.get("image_base_size", 512))
    try:
        base_size = int(base_size)
    except (ValueError, TypeError):
        base_size = 512

    aspect = args.get("aspect_ratio", config.get("image_default_aspect", "square"))
    if aspect == "landscape_16_9":
        w, h = int(base_size * 16 / 9), base_size
    elif aspect == "portrait_9_16":
        w, h = base_size, int(base_size * 16 / 9)
    elif aspect == "landscape_3_2":
        w, h = int(base_size * 1.5), base_size
    elif aspect == "portrait_2_3":
        w, h = base_size, int(base_size * 1.5)
    else:
        w, h = base_size, base_size

    w = (w // 64) * 64
    h = (h // 64) * 64

    width = args.get("width", w)
    height = args.get("height", h)
    add_to_gallery = as_bool(config.get("image_auto_gallery", True))
    add_frame = as_bool(config.get("image_insert_frame", False))

    args_copy = {k: v for k, v in args.items() if k != "prompt"}
    image_model_override = args.get("image_model")

    try:
        result = service.generate_image(prompt, provider_name=provider, width=width,
                                        height=height, status_callback=status_callback,
                                        model=image_model_override, **args_copy)
        if isinstance(result, tuple) and len(result) == 2:
            paths, error_msg = result
            if not paths:
                return json.dumps({"status": "error", "message": error_msg or "Generation failed: No image returned."})
        else:
            paths = result
            if not paths:
                return json.dumps({"status": "error", "message": "Generation failed: No image returned."})
        if provider in ("endpoint", "openrouter"):
            image_model_used = (image_model_override or config.get("image_model") or "").strip() or get_text_model(ctx)
            if image_model_used:
                endpoint = str(config.get("endpoint", "")).strip()
                update_lru_history(ctx, image_model_used, "image_model_lru", endpoint)
        insert_image(ctx, model, paths[0], width, height, title=prompt,
                     description="Generated by %s" % provider,
                     add_to_gallery=add_to_gallery, add_frame=add_frame)
        return json.dumps({"status": "ok", "message": "Image generated and inserted from %s." % provider})
    except Exception as e:
        return json.dumps({"status": "error", "message": str(e)})


def tool_edit_image(model, ctx, args, status_callback=None):
    """Edit the selected image using Img2Img. Replaces selection in place when possible."""
    from plugin.framework.image_utils import ImageService
    from plugin.modules.core.image_tools import get_selected_image_base64, insert_image, replace_image_in_place
    from plugin.modules.core.config import get_config_dict, as_bool, get_text_model, update_lru_history

    source_b64 = get_selected_image_base64(model, ctx=ctx)
    if not source_b64:
        return json.dumps({"status": "error", "message": "No image selected. Please select an image in the document first."})

    config = get_config_dict(ctx)
    service = ImageService(ctx, config)

    prompt = args.get("prompt")
    provider = args.get("provider", config.get("image_provider", "aihorde"))
    add_to_gallery = as_bool(config.get("image_auto_gallery", True))
    add_frame = as_bool(config.get("image_insert_frame", False))

    args_copy = {k: v for k, v in args.items() if k != "prompt"}

    try:
        result = service.generate_image(prompt, provider_name=provider,
                                        source_image=source_b64,
                                        status_callback=status_callback, **args_copy)
        if isinstance(result, tuple) and len(result) == 2:
            paths, error_msg = result
            if not paths:
                return json.dumps({"status": "error", "message": error_msg or "Editing failed: No image returned."})
        else:
            paths = result
            if not paths:
                return json.dumps({"status": "error", "message": "Editing failed: No image returned."})
        if provider in ("endpoint", "openrouter"):
            image_model_used = (config.get("image_model") or "").strip() or get_text_model(ctx)
            if image_model_used:
                endpoint = str(config.get("endpoint", "")).strip()
                update_lru_history(ctx, image_model_used, "image_model_lru", endpoint)
        replaced = replace_image_in_place(ctx, model, paths[0], 512, 512, title=prompt,
                                          description="Edited by %s" % provider,
                                          add_to_gallery=add_to_gallery, add_frame=add_frame)
        if not replaced:
            insert_image(ctx, model, paths[0], 512, 512, title=prompt,
                         description="Edited by %s" % provider,
                         add_to_gallery=add_to_gallery, add_frame=add_frame)
        return json.dumps({"status": "ok", "message": "Image edited and inserted from %s." % provider})
    except Exception as e:
        return json.dumps({"status": "error", "message": str(e)})


def tool_web_research(model, ctx, args, status_callback=None, append_thinking_callback=None):
    import os
    from plugin.modules.core.config import get_api_config, get_config, user_config_dir
    from plugin.framework.http import LlmClient
    from plugin.modules.core.smol_model import LocalWriterSmolModel
    from plugin.contrib.smolagents.agents import ToolCallingAgent
    from plugin.contrib.smolagents.default_tools import DuckDuckGoSearchTool, VisitWebpageTool

    query = args.get("query", "")
    if not query:
        return json.dumps({"status": "error", "message": "Query is required for web search."})

    history_text = args.get("history_text", "")
    context_str = ""
    if history_text:
        # Truncate if extremely long, though the agent will handle it
        if len(history_text) > 4000:
            history_text = "..." + history_text[-4000:]
        context_str = "Below is the previous conversation for context:\n" + history_text + "\n\n"

    try:
        if status_callback:
            status_callback("Sub-agent starting web search: " + query)

        config = get_api_config(ctx)
        max_tokens = int(config.get("chat_max_tokens", 2048))
        max_steps = int(config.get("search_web_max_steps", 20))

        udir = user_config_dir(ctx)
        raw_mb = int(get_config(ctx, "web_cache_max_mb", 50))
        cache_max_mb = 0 if raw_mb <= 0 else max(1, min(500, raw_mb))
        cache_path = os.path.join(udir, "localwriter_web_cache.db") if (udir and cache_max_mb > 0) else None

        smol_model = LocalWriterSmolModel(
            LlmClient(config, ctx), max_tokens=max_tokens,
            status_callback=status_callback,
        )

        instructions = "You are a research assistant. Use the conversation context provided below to resolve any ambiguity in the user's query."
        agent = ToolCallingAgent(
            tools=[
                DuckDuckGoSearchTool(cache_path=cache_path, cache_max_mb=cache_max_mb),
                VisitWebpageTool(cache_path=cache_path, cache_max_mb=cache_max_mb),
            ],
            model=smol_model,
            max_steps=max_steps,
            instructions=instructions,
        )

        task = f"### CONVERSATION HISTORY:\n{history_text or 'None'}\n\n### CURRENT QUERY:\n{query}"
        
        # Always use streaming mode so we can push status heartbeats between steps.
        # This keeps the UI drain loop active and LibreOffice responsive.
        final_ans = None
        from plugin.contrib.smolagents.memory import ActionStep, FinalAnswerStep, ToolCall
        from urllib.parse import urlparse
        
        for step in agent.run(task, stream=True):
            if isinstance(step, ToolCall):
                status_msg = ""
                if step.name == "web_search":
                    q = str(step.arguments.get("query", "")) if isinstance(step.arguments, dict) else ""
                    if len(q) > 25: q = q[:22] + "..."
                    status_msg = f"Search: {q}"
                elif step.name == "visit_webpage":
                    url = str(step.arguments.get("url", "")) if isinstance(step.arguments, dict) else ""
                    domain = urlparse(url).netloc or url[:30]
                    if domain.startswith("www."):
                        domain = domain[4:]
                    status_msg = f"Read: {domain}"
                else:
                    status_msg = str(step.name)

                if status_callback and status_msg:
                    status_callback(f"{status_msg}...")

            elif isinstance(step, ActionStep):
                # Detailed thinking text is optional (controlled by show_search_thinking)
                if append_thinking_callback:
                    msg = f"Step {step.step_number}:\n"
                    if step.model_output:
                        msg += f"{step.model_output.strip()}\n"
                    elif getattr(step, "model_output_message", None) and step.model_output_message.content:
                        msg += f"{str(step.model_output_message.content).strip()}\n"

                    if step.tool_calls:
                        for tc in step.tool_calls:
                            msg += f"Running tool: {tc.name} with {tc.arguments}\n"

                    if step.observations:
                        msg += f"Observation: {str(step.observations).strip()}\n"

                    append_thinking_callback(msg + "\n")
            elif isinstance(step, FinalAnswerStep):
                final_ans = step.output

        return json.dumps({"status": "ok", "message": f'searched for "{query}"', "result": str(final_ans)})
    except Exception as e:
        return json.dumps({"status": "error", "message": f"Web search failed: {str(e)}"})

# ---------------------------------------------------------------------------
# Tool dispatch table
# ---------------------------------------------------------------------------

TOOL_DISPATCH = {
    "get_document_content": tool_get_document_content,
    "apply_document_content": tool_apply_document_content,
    "find_text": tool_find_text,
    # Styles
    "get_document_outline": tool_get_document_outline,
    "get_heading_content": tool_get_heading_content,
    "read_paragraphs": tool_read_paragraphs,
    "insert_at_paragraph": tool_insert_at_paragraph,
    "get_document_stats": tool_get_document_stats,
    "list_styles": tool_list_styles,
    "get_style_info": tool_get_style_info,
    # Comments
    "list_comments": tool_list_comments,
    "add_comment": tool_add_comment,
    "delete_comment": tool_delete_comment,
    # Track changes
    "set_track_changes": tool_set_track_changes,
    "get_tracked_changes": tool_get_tracked_changes,
    "accept_all_changes": tool_accept_all_changes,
    "reject_all_changes": tool_reject_all_changes,
    # Tables
    "list_tables": tool_list_tables,
    "read_table": tool_read_table,
    "write_table_cell": tool_write_table_cell,
}

# Build schema map from existing OpenAI-style list (used by Writer registry wrappers).
_WRITER_SCHEMA_BY_NAME = {}
for item in WRITER_TOOLS:
    func = item.get("function", {})
    name = func.get("name")
    if name:
        _WRITER_SCHEMA_BY_NAME[name] = (
            func.get("description", ""),
            func.get("parameters", {"type": "object", "properties": {}, "required": []}),
        )

_READ_ONLY_PREFIXES = ("get_", "read_", "list_", "find_", "search_", "count_")
_READ_ONLY_NAMES = {"find_text", "web_research"}


def _writer_tool_class(name, dispatch_func):
    """Build a ToolBase subclass that delegates to the legacy TOOL_DISPATCH function."""
    desc, params = _WRITER_SCHEMA_BY_NAME.get(name, ("", {"type": "object", "properties": {}, "required": []}))
    is_mutation = name not in _READ_ONLY_NAMES and not any(name.startswith(p) for p in _READ_ONLY_PREFIXES)

    class _WriterTool(ToolBase):
        def execute(self, ctx, **kwargs):
            status_cb = getattr(ctx, "status_callback", None)
            thinking_cb = getattr(ctx, "append_thinking_callback", None)
            sig = inspect.signature(dispatch_func)
            extra = {}
            if "status_callback" in sig.parameters or "kwargs" in sig.parameters:
                extra["status_callback"] = status_cb
            if "append_thinking_callback" in sig.parameters or "kwargs" in sig.parameters:
                extra["append_thinking_callback"] = thinking_cb
            result_str = dispatch_func(ctx.doc, ctx.ctx, kwargs, **extra)
            try:
                return json.loads(result_str) if isinstance(result_str, str) else result_str
            except (json.JSONDecodeError, TypeError):
                return {"status": "error", "message": "Invalid tool response"}

    _WriterTool.name = name
    _WriterTool.description = desc
    _WriterTool.parameters = params
    _WriterTool.doc_types = ["writer"]
    _WriterTool.tier = "core"
    _WriterTool.is_mutation = is_mutation
    return _WriterTool


_writer_registry = ToolRegistry(services={})
_writer_registry.register(WebResearchTool())
_writer_registry.register(GenerateImageTool())
_writer_registry.register(EditImageTool())

for _name, _func in TOOL_DISPATCH.items():
    _writer_registry.register(_writer_tool_class(_name, _func)())

# Single source of truth for Writer tool schemas (panel + MCP).
WRITER_TOOLS = _writer_registry.get_openai_schemas(doc_type="writer")


def _truncate_for_log(obj, max_len=200):
    """Return a copy safe for logging: long strings truncated, dicts/lists traversed."""
    if isinstance(obj, str):
        return obj if len(obj) <= max_len else obj[:max_len] + "...[truncated]"
    if isinstance(obj, dict):
        return {k: _truncate_for_log(v, max_len) for k, v in obj.items()}
    if isinstance(obj, list):
        return [_truncate_for_log(x, max_len) for x in obj]
    return obj


def execute_tool(tool_name, arguments, doc, ctx, status_callback=None, append_thinking_callback=None):
    """Execute a tool by name. Returns JSON result string."""
    # If the tool is a writer operation, it might mutate the document.
    # Invalidate cache if it's not a 'get' or 'read' or 'list' tool.
    is_mutation = not (tool_name.startswith("get_") or tool_name.startswith("read_") or tool_name.startswith("list_"))
    if is_mutation:
        DocumentCache.invalidate(doc)

    tool = _writer_registry.get(tool_name)
    if tool is not None:
        try:
            agent_log("document_tools.py:execute_tool", "Tool call",
                      data={"tool": tool_name, "arguments": _truncate_for_log(arguments or {})},
                      hypothesis_id="C,E")
            tctx = ToolContext(
                doc, ctx, "writer", {}, "chatbot",
                status_callback=status_callback,
                append_thinking_callback=append_thinking_callback,
            )
            result = _writer_registry.execute(tool_name, tctx, **(arguments or {}))
            agent_log("document_tools.py:execute_tool", "Tool result",
                      data={"tool": tool_name, "result_snippet": str(result)[:120]},
                      hypothesis_id="C,E")
            return json.dumps(result) if isinstance(result, dict) else result
        except Exception as e:
            return json.dumps({"status": "error", "message": str(e)})

    func = TOOL_DISPATCH.get(tool_name)
    if not func:
        return json.dumps({"status": "error", "message": "Unknown tool: %s" % tool_name})
    try:
        agent_log("document_tools.py:execute_tool", "Tool call",
                  data={"tool": tool_name, "arguments": _truncate_for_log(arguments or {})},
                  hypothesis_id="C,E")
        sig = inspect.signature(func)
        kwargs = {}
        if "status_callback" in sig.parameters or "kwargs" in sig.parameters:
            kwargs["status_callback"] = status_callback
        if "append_thinking_callback" in sig.parameters or "kwargs" in sig.parameters:
            kwargs["append_thinking_callback"] = append_thinking_callback

        result = func(doc, ctx, arguments or {}, **kwargs)
        agent_log("document_tools.py:execute_tool", "Tool result",
                  data={"tool": tool_name, "result_snippet": (result or "")[:120]},
                  hypothesis_id="C,E")
        return result
    except Exception as e:
        return json.dumps({"status": "error", "message": str(e)})
